\chapter{Evaluation}
Part of the difficulty of this project was going through several iterations of understandings of the data, and how it needed to be interpreted. This meant that the requirements only really became clear very late in the project. However once they were apparent, development from then on went very smoothly.

The end result is functional, and meets all of the achievable criteria so I believe the design decisions were correct, and the implementation done in a clean and efficient manner. The codebase produced is only around 700 lines for the importation script and website combined, this isn't a terribly useful metric, but it does show that the code is at least concise.

The use of NodeJS and MongoDB does set this project apart from older similar projects, that use Perl and PostgreSQL. However there is a clear shift in the technologies used for web development, as Perl is on the decline\cite{perl-market}, and newer technologies like NodeJS are taking it's place. 

Once the website was deployed to the university servers, the researchers were able to use it for a more extended period, and appeared to be very happy with what was produced. They did make suggestions of additional features that could have been included, but these weren't discussed during the project so weren't really in scope. In the future though it would definitely be an interesting project to expand the system to include some of these features such as a comparison tool between genes.

If the project were to be redone from the start I would try to talk to the source of the data sooner and ideally schedule a session with the researchers to look over the data and hopefully unpick what it all meant a lot sooner than we did. 

I'm very pleased with the end result of the project, it is a nicely developed clean piece of software that meets it's basic functional requirements. The area that really could have been improved upon was the amount of time it took to get to grips with the data. If I had had the understanding of it much earlier in the project, there could have been more features developed that would have helped the researchers a lot more than what I was able to produce. One area that I would have loved to be able to explore was creating a comparison tool, which would allow them to compare two or more genes directly. 

This would have added a lot more complexity to the project, but considering how smoothly the development of the application went, once the data was understood correctly, I think there would have been plenty of time. The actual development of the database and website did only take around a week, so there was a lot more room for new features, had the data been understood earlier. 

The application was built with very robust software engineering principles, and the code is a testament to how cleanly it was developed, there are very few code smells\cite{smells} throughout the code. This is mostly thanks to the discipline enforced by having linters and automated testing. The only area that falls down in this regard is the amount of unit tests. As the project stands there are only a handful of unit tests to check the finding of coding sequences. Ideally it would be good to expand the testing to cover the Pug templates, the controller logic, and the search functionality. 

Unfortunately by the time the data was understood enough to develop the application fully, there was not enough time to test these features and write up this report. 

% \section{Differences in Bioinformatics and Computer Science}
% One interesting area of this project has been observing the relative immaturity of the bioinformatics field, when compared to computer science. From studying bioinformatics and researching the most common methods of manipulating and analysing the data gathered, a trend was in the solutions being used was observed. 

% In computer science, tools are highly developed and have evolved to a very stable state and the best tools are known to be industry standards for their specialised purposes. 

% However in bioinformatics a combination of factors including the relative youth of the field and the large number of competing projects that don't collaborate due to competing for research publications; there have been a wide array of tools created, often by biologists with no software engineering experience, none of which have been adopted and honed as the \texti{de facto} standard. 

% This means that for every task in the bioinformatics space there is often many different solutions offered, to what can be a very simple problem. An example of this is the simple task of splitting a fasta file up into several chunks, this should be a very simple problem to solve, and once it's been solved once that tool should become the one tool to complete that task. 

% Unfortunately when trying to do this, several tools were discussed on biostars forum\cite{biostars}, none of which worked for the non-redundant database that was trying to be split. Eventually a tool called Genometools made by Gordon Gremme et al.\cite{genometools} was able to complete the task, yet it wasn't mentioned in the earlier discussion on the online forum. 

% Another example of the differences are markup languages, there are really only three major competing standards, XML, JSON and YAML, and they each have their own niche. However in bioinformatics there seems to be many ways to represent data from alignments or sequences, none of which use one of the aforementioned standards. Fasta is appearing to be the most mature way however there are so many standards, tab separated, GFF3, EMBL and SAM files to name a few. 

% As a computer scientist it seems unusual to have so many competing standards, instead of a standard mark up language to represent the data. Fasta could very easily be replaced by YAML, which would save a huge amount of developer time as they wouldn't have to produce or implement a fasta parser in their language of choice, as YAML can be natively read by most modern languages. 
